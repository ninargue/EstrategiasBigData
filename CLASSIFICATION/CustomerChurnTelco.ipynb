{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción del Customer Churn\n",
    "\n",
    "***¿Qué es el Customer Churn o Abandono del cliente?***\n",
    "\n",
    "Es una de las métricas más importantes que debe evaluar una empresa en *crecimiento*. Esta métrica puede darle a los directivos un acercamiento a la realidad, sobre el comportamiento en la retención de sus clientes. Es difícil medir el éxito si no se miden también los inevitables fracasos. Si bien, se hace un esfuerzo por retener a los clientes, no siempre es posible sin realizar un estudio y seguimiento apropiado. Es ahí donde el concepto de la rotación de clientes entra a jugar un papel fundamental.\n",
    "\n",
    "**Existe distintas clasificación de Churn:**\n",
    "- Churn Voluntario: el cliente abandona de manera voluntaria la compra/uso del producto o servicio.\n",
    "- Churn Involuntario: la empresa le suspende al cliente el suministro del producto o servicio.\n",
    "- Churn No contractual: el cliente no está obligado a guardar relación con la empresa a través de un contrato, sin embargo abandona la compra/uso del producto o servicio.\n",
    "\n",
    "**Algunas causas del Churn voluntario:**\n",
    "- Falta de uso\n",
    "- Servicio/producto deficiente\n",
    "- Mejor precio/calidad/disponibilidad en otro producto/servicio\n",
    "\n",
    "**Algunos ejemplos de abandono de clientes (Churn):**\n",
    "- El cliente compra en una tienda diferente\n",
    "- El cliente deja de adquirir un servicio o producto\n",
    "- El cliente cancela un servicio que está bajo contrato\n",
    "- Caducidad de la tarjeta de crédito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de visualización de dataframes\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco = pd.read_csv('data/Telco_Churn.csv')\n",
    "telco.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero revisaremos la estructura de nuestro conjunto de datos de clientes, que se ha precargado en un DataFrame llamado Telco. *Poder verificar la estructura de los datos es un paso fundamental en el proceso de modelado de abandono.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción de columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contenido del Dataset:**\n",
    "\n",
    "Cada fila representa un cliente, cada columna contiene los atributos del cliente, presentes en el último mes. \n",
    "\n",
    "El conjunto de datos incluye información sobre: \n",
    "- 'Churn': Yes/No; el cliente SI/NO se fue con otro proveedor de servicio\n",
    "- 'Account_Length': Número de meses desde que el cliente se suscribió\n",
    "- 'Vmail_Message': Número de mensajes de texto enviados\n",
    "- 'Day_Mins': Minutos promedios consumidos en el día\n",
    "- 'Eve_Mins': Minutos promedios consumidos en la tarde\n",
    "- 'Night_Mins': Minutos promedios consumidos en la noche\n",
    "- 'Intl_Mins': Minutos promedios en llamadas internacionales consumidos en el día\n",
    "- 'CustServ_Calls': Número de llamadas realizadas a servicio al cliente\n",
    "- 'Intl_Plan': Yes/No posee servicio de llamadas internacionales\n",
    "- 'Vmail_Plan': Yes/No posee servicio de mensaje de voz\n",
    "- 'Day_Calls': Promedio de Llamadas realizadas en el día\n",
    "- 'Day_Charge': Monto promedio de carga en doláres en llamadas diarias\n",
    "- 'Eve_Calls': Promedio de Llamadas realizadas en la tarde\n",
    "- 'Eve_Charge': Monto promedio de carga en doláres en llamadas en la tarde\n",
    "- 'Night_Calls': Promedio de Llamadas realizadas en la noche\n",
    "- 'Night_Charge': Monto promedio de carga en doláres en llamadas nocturnas\n",
    "- 'Intl_Calls': Promedio de Llamadas realizadas en el día\n",
    "- 'Intl_Charge': Monto promedio de carga en doláres en llamadas internacionales\n",
    "- 'State': Código de Estado del país (Estados Unidos)\n",
    "- 'Area_Code': código de área telefónica\n",
    "- 'Phone': Número de teléfono"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caracterizacón del problema\n",
    "- Clasificación binaria\n",
    "- Tipo desbalanceado\n",
    "\n",
    "La característica de particular interés en el problema o target, es el `Churn`, que puede tomar dos valores (yes/no) que indican si el cliente ha abandonado o no. \n",
    "\n",
    "    Exploremos la feature -Churn-, para contestar a la pregunta: \n",
    "\n",
    "¿Cuántos churn/no churn tiene el conjunto de datos? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = telco.Churn.value_counts()\n",
    "print(f\"\\tCantidad de No Churn/Churn:\\n{freq}\\n\\n  % de No Churn/Churn:\\n{round(freq/len(telco)*100, 2)}\\n\\n\")\n",
    "ax = freq.plot.barh()\n",
    "for x, y, c, l in zip(freq.values-200, [0.01, 0.99], np.array(freq/len(telco)*100), [\"top\", 'right']):\n",
    "    ax.text(x, y, str(round(c, 2)) + '%', ha='center', va='center', color='w', weight='bold')\n",
    "    ax.spines[l].set_visible(False)\n",
    "plt.title('Churn: Distribución de clases')\n",
    "# ax.set_frame_on(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> A simple vista podemos apreciar que se trata de un caso clases binarias desbalanceadas -> la balanza se inclina hacia una de las categorias ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Exploratorio de los datos\n",
    "\n",
    "Se explora la variable target `Churn`, para ver si hay diferencias en los atributos, entre quiénes abandonan y no abandonan.\n",
    "\n",
    "Nos podemos hacer preguntas interesantes como:\n",
    "    \n",
    "    ¿Un cliente que abandona...\n",
    "- realiza más llamadas a servicio al cliente?\n",
    "- disminuye el consumo de llamadas?\n",
    "- realiza cargas de menor monto?\n",
    "- se ubican en determinada región geográfica?\n",
    "\n",
    "Podemos plantear las siguientes\n",
    "\n",
    "***Hipótesis:***\n",
    "1. Los clientes que abandonan realizan más llamadas de servicio al cliente\n",
    "1. Los clientes que abandonan realizan menos envíos de mensajes de texto\n",
    "1. Los clientes que abandonan realizan más llamadas en el día\n",
    "1. Los clientes que abandonan realizan más llamadas en la tarde\n",
    "1. Los clientes que abandonan cargan un monto mayor a su cuenta\n",
    "1. Los clientes que abandonan y tienen planes internacionales realizan más llamadas de servicio al cliente\n",
    "1. Los clientes que abandonan y tienen planes de correo de voz realizan más llamadas de servicio al cliente\n",
    "\n",
    "Ahora tratemos de corroborar estas hipótesis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Visualización de los valores medios de distintas features agrupados por NO_CHURN/CHURN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedios = round(telco.drop('Area_Code', axis=1).groupby(['Churn']).mean(), 2)\n",
    "promedios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_medianos = round(telco.drop('Area_Code', axis=1).groupby(['Churn']).median(), 2)\n",
    "valores_medianos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedios.T.plot.bar(figsize=(16, 6))\n",
    "plt.title('Valores promedios de las variables - Grupos Churn/No Churn', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de tipos de variables continuas y enteras para realizar los análisis exploratorios\n",
    "var_continuas = list(telco.select_dtypes(include=['float64']).columns)\n",
    "\n",
    "var_discretas = list(telco.select_dtypes(include=['int64']).columns)\n",
    "var_discretas.remove('Area_Code')\n",
    "\n",
    "print(f\"Variables continuas:\\n {var_continuas}\\n\\nVariables discretas:\\n {var_discretas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables continuas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Visualicemos las distribuciones de las features de tipo continuas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = var_continuas\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(features):\n",
    "    ax = plt.subplot(int(np.ceil(len(features)/3)), 3, i+1)\n",
    "    sns.histplot(telco[feature], ax=ax, kde=True)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "features = var_continuas\n",
    "rows = int(np.ceil(len(features)/3))\n",
    "for i, feature in enumerate(features):\n",
    "    ax = plt.subplot(rows, 3, i+1)\n",
    "    sns.histplot(telco[telco['Churn']=='no'][feature], ax=ax, kde=True, color='green')\n",
    "    sns.histplot(telco[telco['Churn']=='yes'][feature], ax=ax, kde=True, color='red')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables Discretas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "features = var_discretas\n",
    "rows = int(np.ceil(len(features)/3))\n",
    "for i, feature in enumerate(features):\n",
    "    ax = plt.subplot(rows, 3, i+1)\n",
    "    sns.countplot(x = feature, data = telco, ax=ax, hue='Churn')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa ciertas diferencias en las medias de los valores de:\n",
    "- Vmail_Message\n",
    "- Day_Mins\n",
    "- Eve_Mins\n",
    "- CustServ_Calls\n",
    "- Day_Charge\n",
    "\n",
    "... exploraremos un poco más los datos para ver qué patrones conseguimos en estos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### => 1) Ha: *Los clientes que abandonan realizan más llamadas a servicio al cliente*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sns.boxplot(x = 'Churn', y = 'CustServ_Calls', data = telco, ax=axs[0])\n",
    "axs[0].set_title('Distribución de la cant de llamadas \\na servicio al cliente')\n",
    "sns.boxplot(x = 'Churn', y = 'CustServ_Calls', data = telco, sym='', ax=axs[1])\n",
    "axs[1].set_title('Distribución de la cant de llamadas \\na servicio al cliente (sin outliers)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### => 2) Ha: *Los clientes que abandonan realizan menos envíos de mensajes de texto*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Churn', y = 'Vmail_Message', data = telco)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Más exploración a fondo..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Exploremos con más detalle la feature `Churn` para ver si se encuentran algunas diferencias entre quienes abandonan y no abandonan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frecuencia o Cantidad por número de llamadas a Servicio al cliente\n",
    "df_Freq = pd.crosstab(telco['CustServ_Calls'], telco['Churn'], normalize=False, margins=True)\n",
    "print(f\"Cantidad de clientes: para Número de llamadas a servicio al cliente mensuales vs Churn/No Churn:\\n{'-'*35}\\n{df_Freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo se interpreta esto? \n",
    "\n",
    "76 clientes con perfil de abandono realizaron 4 llamadas mensuales al servicio al cliente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porcentajes del total de llamadas por Número de llamadas a Servicio al cliente\n",
    "df_FreqRel = round(pd.crosstab(telco['CustServ_Calls'], telco['Churn'], normalize=True, margins=True), 4)*100\n",
    "print(f\"Porcentaje de clientes (del total): para Número de llamadas a servicio al cliente mensuales vs Churn/No Churn:\\n{'-'*40}\\n{df_FreqRel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo se interpreta esto? \n",
    "\n",
    "2,28% de los clientes con perfil de abandono del total de clientes, realizaron 4 llamadas mensuales al servicio al cliente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidades condicionadas al comportamiento Churn/No Churn (expresadas en porcentajes)\n",
    "table = pd.crosstab(telco['CustServ_Calls'], telco['Churn'], normalize=True, margins=True)\n",
    "table_ProbCond = round(table/table.loc['All',], 4)*100\n",
    "print(f\"Probabilidad Condicional: para Número de llamadas a servicio al cliente mensuales vs Churn/No Churn:\\n{'-'*40}\\n{table_ProbCond}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero...¿Cómo se interpreta esto? \n",
    "\n",
    "15,73% de los clientes con perfil de abandono realizaron 4 llamadas mensuales al servicio al cliente "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### => 3) Ha: *Los clientes que abandonan realizan más llamadas en el día*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Churn', y = 'CustServ_Calls', data = telco)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### => 4) Ha: *Los clientes que abandonan realizan más llamadas en la tarde*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Churn', y = 'Eve_Mins', data = telco)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.groupby(['Churn'])['Eve_Mins'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### => 5) Ha: *Los clientes que abandonan cargan un monto mayor a su cuenta*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Churn', y = 'Night_Mins', data = telco)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.groupby(['Churn'])['Night_Mins'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### => 6) Ha: *Los clientes que abandonan y tienen planes internacionales realizan más llamadas de servicio al cliente*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Churn', y = 'CustServ_Calls', data = telco, hue = \"Intl_Plan\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.groupby(['Churn', 'Intl_Plan'])['CustServ_Calls'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### => 7) Ha: *Los clientes que abandonan y tienen planes de correo de voz realizan más llamadas de servicio al cliente*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Churn', y = 'CustServ_Calls', data = telco, hue = \"Vmail_Plan\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.groupby(['Churn', 'Vmail_Plan'])['CustServ_Calls'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparación de datos**\n",
    "\n",
    "Luego de haber realizado un análisis exploratorio y teniendo una mejor comprensión del conjunto de datos, es necesario realizar un preprocesamiento de los datos para prepararlos para la fase de modelado. Para ello, se deben tener algunas consideraciones:\n",
    "\n",
    "    - Supuestos del modelo:\n",
    "    Muchos modelos de aprendizaje automático hacen ciertas suposiciones sobre cómo se distribuyen los datos. Si las características del conjunto de datos no cumplen con estos supuestos, los resultados de los modelos no serán confiables. Es por eso que la etapa de preprocesamiento de datos es tan crítica.\n",
    "\n",
    "    - Tipos de datos:\n",
    "    La mayoría de modelos de aprendizaje automático solo aceptan tipos de datos numéricos. Por esto, las variables categóricas se deben codificar. Las variables categóricas nominales y categóricas ordinales se codifican de manera distinta.\n",
    "    \n",
    "Variables nominales --> One Hot Encoding\n",
    "\n",
    "<img src='https://etlpoint.com/wp-content/uploads/2020/07/77.png' width=500 height=250>\n",
    "\n",
    "\n",
    "Variables dictómicas, binarias o Bernoulli --> Label Encoding/Diccionario/np.where()\n",
    "\n",
    "<img src='https://codesource.io/wp-content/uploads/2020/10/s_42397C87DD7A68DD44664F8BD43E489E8A1588FCDBD63C1390CCDB3E546DA556_1600447755931_labelen.jpg' width=180 height=90>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Codificación de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación de variables dicotómicas:\n",
    "\n",
    "Una *variable dicotómica* es aquella que toma uno de los dos únicos valores posibles, cuando se observa o mide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas de datos tipo object\n",
    "telco.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaries_var = ['Churn', 'Intl_Plan', 'Vmail_Plan']\n",
    "print(f\"Variables dicotómicas antes de codificar:\\n{telco[binaries_var].head(3)}\")\n",
    "\n",
    "# Diccionario para realizar la codificación\n",
    "dict_bin = {'no': 0, 'yes': 1}\n",
    "\n",
    "# Variables dicotómicas a codificar\n",
    "binaries_var = ['Churn', 'Intl_Plan', 'Vmail_Plan']\n",
    "\n",
    "# Codificación\n",
    "classes_bin = telco[binaries_var].apply(lambda x: x.replace(dict_bin))\n",
    "print(f\"\\n\\nVariables dicotómicas codificadas:\\n{classes_bin.head(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si necesitas enfocarnos más en una categoría de la variables, podríamos usar este modo de codificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un nuevo dataframe para preparar los datos para el modelo\n",
    "# Se elimina la columna de Estado, no vamos a trabajar con ella para simplificar el análisis\n",
    "# Se elimina la columna de los números telefónicas, es una variable de valores únicos y no aporta información\n",
    "# De igual manera sucede con la columna del código de área\n",
    "modeling_data = telco.drop(columns=['State', 'Phone', 'Area_Code']).copy()\n",
    "modeling_data['Churn'] = np.where(modeling_data['Churn']=='yes', 1, 0)\n",
    "modeling_data['Intl_Plan'] = np.where(modeling_data['Intl_Plan']=='no', 1, 0)\n",
    "modeling_data['Vmail_Plan'] = np.where(modeling_data['Vmail_Plan']=='no', 1, 0)\n",
    "\n",
    "# Veamos cómo quedan estas columnas\n",
    "modeling_data[binaries_var].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "\n",
    "[LabelEncoder Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Ejemplo de Label Encoding\n",
    "\n",
    "# Instanciar LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Ajuste los datos\n",
    "le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
    "\n",
    "# Etiquetas de clases encontradas\n",
    "print(f\"Clases encontradas: {list(le.classes_)}\\n\")\n",
    "\n",
    "# Lista de categorias a codificar\n",
    "cities = [\"tokyo\", \"tokyo\", \"paris\", 'amsterdam']\n",
    "\n",
    "# Codificación de la lista de categorias\n",
    "cod_cities = list(le.transform(cities))\n",
    "print(f'De Categorias a códigos: {cities} --> {cod_cities}')\n",
    "\n",
    "inv_labels = list(le.inverse_transform(cod_cities))\n",
    "print(f'De códigos a categorias: {cod_cities} --> {inv_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Lista de clases de las variables\n",
    "classes = telco['Churn'].unique().tolist()\n",
    "\n",
    "# Ajuste a las clases\n",
    "le.fit(classes)\n",
    "\n",
    "# Aplicar la codificación a cada una de las columnas\n",
    "classes_bin_label = telco[binaries_var].apply(lambda x: list(le.transform(x)))\n",
    "\n",
    "# Resultado de la codificación\n",
    "classes_bin_label.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La dicotomización o binarización consiste en tratar datos continuos (previamente categorizados) o variables politómicas como si fueran variables binarias.\n",
    "\n",
    "**Implicaciones de utilizar [`get_dummies()`](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) de pandas y [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder) de sklearn:**\n",
    "\n",
    "OneHotEncoder de sklearn guarda las categorías ajustadas para su posterior transformación, lo que es extremadamente útil cuando se requiere aplicar el mismo preprocesamiento de datos en un nueo conjunto de datos.\n",
    "\n",
    "--> Codificación de features politómicas (Dicotomización):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_labels_state = pd.get_dummies(telco['State'], drop_first=False)\n",
    "print(bin_labels_state.shape)\n",
    "bin_labels_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_labels_state = pd.get_dummies(telco['State'], drop_first=True)\n",
    "print(bin_labels_state.shape)\n",
    "bin_labels_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(telco[['State']])\n",
    "\n",
    "bin_labels_state = ohe.transform(telco[['State']])\n",
    "bin_labels_state = pd.DataFrame(bin_labels_state.toarray(), columns=ohe.categories_, dtype='int')\n",
    "print(bin_labels_state.shape)\n",
    "bin_labels_state.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Algunos algoritmos son muy sensibles a características que abarcan diversos grados de magnitud, rango y unidades. \n",
    "\n",
    "Aquí está lo curioso del escalado de funciones: mejora (significativamente) el rendimiento de algunos algoritmos de aprendizaje automático y no funciona en absoluto para otros. ¿Cuál podría ser la razón detrás de esta peculiaridad?\n",
    "\n",
    "Los algoritmos de aprendizaje automático como la `regresión lineal`, la `regresión logística`, la `red neuronal`, que utilizan el descenso de gradiente como técnica de optimización, requieren escalar los datos.\n",
    "\n",
    "El escalado de datos garantiza que el descenso del gradiente se mueva suavemente hacia los mínimos y que los pasos del descenso del gradiente se actualicen al mismo ritmo para todas las entidades.\n",
    "\n",
    "Tener características en una escala similar puede ayudar a que el descenso del gradiente converja más rápidamente hacia los mínimos.\n",
    "\n",
    "Los algoritmos de distancia como `KNN`, `K-Means` y `SVM` son los más afectados por el rango amplios de las variables. Esto se debe a que estos utilizan distancias entre puntos de datos para determinar su similitud.\n",
    "\n",
    "Existe la posibilidad de que se otorgue un mayor peso a las características con mayor magnitud. Esto afectará el rendimiento del algoritmo y, que esté sesgado hacia una característica.\n",
    "\n",
    "El escalado permite que todas las características contribuyan por igual al resultado.\n",
    "\n",
    "Los algoritmos basados en `Árboles de Decisión`, son bastante insensibles a la escala de las características. Un árbol de decisiones solo divide un nodo en función de una única característica. El árbol de decisión divide un nodo en una característica que aumenta la homogeneidad del nodo. Esta división de una característica no se ve influenciada por otras características.\n",
    "\n",
    "**Técnicas de Escalado:**\n",
    "\n",
    "La `normalización` es una técnica de escalado en la que los valores se cambian y se vuelven a escalar para que terminen oscilando entre 0 y 1. También se conoce como escalado Min-Max ([Sklearn MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler) ).\n",
    "\n",
    "La `estandarización` es otra técnica de escalado donde los valores se centran alrededor de la media con una desviación estándar unitaria. La media del atributo es cero y la distribución resultante tiene una desviación estándar de 1 ([Sklearn StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)).\n",
    "\n",
    "¿Cuál es la diferencia entre normalización y estandarización? Estas son dos de las técnicas de escalado de características más utilizadas en el aprendizaje automático, pero existe un nivel de ambigüedad en su comprensión. ¿Cuándo deberías usar qué técnica?\n",
    "\n",
    "                    NORMALIZACIÓN                        ESTANDARIZACIÓN\n",
    "\n",
    "<img src='https://i0.wp.com/datasharkie.com/wp-content/uploads/rescaling.png?fit=328%2C92&ssl=1' width=400 height=200>      <img src='https://ichi.pro/assets/images/max/640/1*Ap_7t_-luGSaAVgc7kl7qA.png' width=200 height=100>\n",
    "\n",
    "**¿Normalización o Estandarización?**\n",
    "\n",
    "- *Normalización*: Cuando sabe que la distribución de sus datos no sigue una distribución gaussiana. Puede ser útil en algoritmos que no asumen ninguna distribución de los datos como `KNN` y `Redes Neuronales`.\n",
    "\n",
    "- *Estandarización*: puede ser útil cuando los datos siguen una distribución gaussiana (no es una regla). \n",
    "\n",
    "A diferencia de la normalización, la estandarización no tiene un rango límite. Sí tiene valores atípicos en sus datos, no se verán afectados por la estandarización.\n",
    "\n",
    "La elección de utilizar la normalización o la estandarización dependerá de su problema y del algoritmo de aprendizaje automático que esté utilizando. No existe una regla estricta y rápida que le indique cuándo normalizar o estandarizar sus datos. Siempre puede comenzar ajustando su modelo a datos sin procesar, normalizados y estandarizados y comparar el rendimiento para obtener los mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instanciar StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Selección de variables para escalar (tomamos las variables continuas)\n",
    "select_vars = var_continuas\n",
    "\n",
    "# Medidas de Resumen Estadístico de variables antes de escalar\n",
    "summary = round(telco[select_vars[:4]].describe(), 3)\n",
    "print(f\"Medidas de Resumen Estadístico de variables a escalar:\\n\\n{summary}\")\n",
    "\n",
    "# modeling_data[select_vars] \n",
    "modeling_data[select_vars] = scaler.fit_transform(modeling_data[select_vars])\n",
    "\n",
    "# Resumen de medidas estadísticas post escalado\n",
    "std_summary = round(modeling_data[select_vars[:4]].describe(), 3)\n",
    "print(f\"\\n\\nMedidas de Resumen Estadístico de variables estandarizadas:\\n\\n{std_summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Instanciar StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Selección de variables para escalar (tomamos las variables continuas)\n",
    "select_vars = var_continuas\n",
    "\n",
    "# Medidas de Resumen Estadístico de variables antes de escalar\n",
    "summary = round(telco[select_vars[:4]].describe(), 3)\n",
    "print(f\"Medidas de Resumen Estadístico de variables a escalar:\\n\\n{summary}\")\n",
    "\n",
    "# modeling_data[select_vars] \n",
    "var_norm = scaler.fit_transform(modeling_data[select_vars])\n",
    "var_norm = pd.DataFrame(var_norm, columns=select_vars)\n",
    "\n",
    "# Resumen de medidas estadísticas post escalado\n",
    "std_summary = round(var_norm[select_vars[:4]].describe(), 3)\n",
    "print(f\"\\n\\nMedidas de Resumen Estadístico de variables estandarizadas:\\n\\n{std_summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Day_Mins', 'Intl_Mins']\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "for i, feature in enumerate(features):\n",
    "    ax = plt.subplot(1, 2, i+1)\n",
    "    sns.histplot(x = feature, data = telco, ax=ax, hue='Churn')\n",
    "    plt.suptitle('Antes de Estandarización')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "for i, feature in enumerate(features):\n",
    "    ax = plt.subplot(1, 2, i+1)\n",
    "    sns.histplot(x = feature, data = modeling_data, ax=ax, hue='Churn')\n",
    "    plt.suptitle('Post-Estandarización')\n",
    "    plt.tight_layout()\n",
    "\n",
    "var_norm['Churn'] = telco['Churn']\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "for i, feature in enumerate(features):\n",
    "    ax = plt.subplot(1, 2, i+1)\n",
    "    sns.histplot(x = feature, data = var_norm, ax=ax, hue='Churn')\n",
    "    plt.suptitle('Post-Normalización')\n",
    "    plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste del Modelo y predicción de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de variables categorias\n",
    "variable_excluir = ['Churn', 'State', 'Phone', 'Area_Code']\n",
    "var_categoricas = list(telco.select_dtypes(include='object').drop(columns=variable_excluir, errors='ignore').columns)\n",
    "var_categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de variables predictoras\n",
    "X_columns = telco.select_dtypes(exclude='object').drop(columns=variable_excluir, errors='ignore').columns\n",
    "X_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armado de dataframes para modelar (para probar un modelo con datos sin escalar)\n",
    "data_X = pd.concat([modeling_data[var_categoricas], telco[X_columns]], axis=1)\n",
    "data_y = modeling_data[['Churn']]\n",
    "data_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear conjuntos de entrenamiento y de prueba\n",
    "\n",
    "El tamaño de sus conjuntos de entrenamiento y prueba influye en el rendimiento del modelo. Los modelos aprenden mejor cuando tienen más datos de entrenamiento. Sin embargo, existe el riesgo de que se ajusten demasiado a los datos de entrenamiento y no generalice bien respecto a los datos nuevos; por lo que para evaluar correctamente la capacidad del modelo para generalizar, necesita suficientes datos de prueba. Como resultado, existe un importante equilibrio y compensación entre la cantidad que usa para el entrenamiento y la cantidad que tiene para las pruebas.\n",
    "\n",
    "Para grandes cantidades de instancias de datos, bastará con un porcentaje pequeño para el conjunto de test.\n",
    "\n",
    "Ver: [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Regresión Logistica\n",
    "\n",
    "[LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instanciar el clasificador\n",
    "clf_LR = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "\n",
    "# Ajustar el modelo de clasificación\n",
    "clf_LR.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Calcular las predicciones\n",
    "y_pred = clf_LR.predict(X_test)\n",
    "\n",
    "# Calcular accuracy\n",
    "print('Accuracy en test:', clf_LR.score(X_test, y_test), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Random Forest\n",
    "\n",
    "[RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instanciar el clasificador\n",
    "clf_RF = RandomForestClassifier(random_state=28)  # class_weight='balanced_subsample'\n",
    "\n",
    "# Ajustar el modelo de clasificación a los datos de entrenamiento\n",
    "clf_RF.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Calcular las predicciones\n",
    "y_pred = clf_RF.predict(X_test)\n",
    "\n",
    "# Calcular accuracy\n",
    "print('Accuracy en test:', clf_RF.score(X_test, y_test), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de Confusión\n",
    "\n",
    "<img src=\"../images/confusion_matrix.png\" alt=\"confusion matrix\" align=\"left\"/>\n",
    "\n",
    "$$ $$\n",
    "$$ $$\n",
    "$$Accuracy=\\frac{\\Sigma (TP + TN)}{\\Sigma(TP + FP + TN + FN)}$$\n",
    "\n",
    "$$Precision=\\frac{\\Sigma TP}{\\Sigma(TP + FP)}$$\n",
    "\n",
    "$$Recall=\\frac{\\Sigma TP}{\\Sigma(TP + FN)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- PRECISION: de las etiquetas positivas predichas, qué porcentaje es predicha correctamente.\n",
    "- RECALL: de las etiquetas positivas reales, qué porcentaje es predicha correctamente.\n",
    "- ESPECIFICIDAD: de las etiquetas negativas reales, qué porcentaje es predicha correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Veamos la matriz de c\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_mat.ravel()\n",
    "conf_mat = pd.DataFrame(conf_mat, columns=['No Churn', 'Churn'], index=['No Churn', 'Churn'])\n",
    "sns.heatmap(conf_mat, annot=True, fmt='.2f', linewidths=1, cbar=False)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('Actual Label', fontsize=12)\n",
    "plt.title('Confusion Matrix', fontdict={'fontsize':14, 'color':'blue', 'fontweight':'bold'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the confusion matrix (porcentual values)\n",
    "conf_mat = confusion_matrix(y_test, y_pred, normalize='all')*100\n",
    "conf_mat = pd.DataFrame(conf_mat, columns=['No Churn', 'Churn'], index=['No Churn', 'Churn'])\n",
    "sns.heatmap(conf_mat, annot=True, fmt='.2f', linewidths=1, cbar=False)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('Actual Label', fontsize=12)\n",
    "plt.title('Confusion Matrix', fontdict={'fontsize':14, 'color':'blue', 'fontweight':'bold'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Resumiendo las Métricas de Clasificación, en el contexto del problema que se está abordando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'- Número de etiquetas reales positivas (Churn): {sum(y_test[\"Churn\"]==1)}')\n",
    "print(f'- Número de etiquetas reales negativas (No Churn): {sum(y_test[\"Churn\"]==0)}\\n')\n",
    "print(f'- El clasificador tuvo {tp + tn} ({tp} + {tn}) predicciones correctas')\n",
    "print(f'- {tp} de las predicciones son verdaderos positivos (TP)')\n",
    "print(f'- {tn} de las predicciones son verdaderos negativos (TN)')\n",
    "print(f'- {fp} de las predicciones son falsos positivos (FP)')\n",
    "print(f'- {fn} de las predicciones son falsos negativos (FN)')\n",
    "print(f'- La exactitud (accuracy) es {round((tp + tn)/(tp + tn + fp + fn)*100, 2)} % = ({tp} + {tn})/({tp} + {tn} + {fp} + {fn})*100')\n",
    "print(f'- La precisión es de {round(tp/(tp + fp)*100, 2)} = ({tp})/({tp} + {fp})*100.')\n",
    "print(f'- La sensibilidad (recall) es de {round(tp/(tp + fn)*100, 2)} = ({tp})/({tp} + {fn})*100.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
