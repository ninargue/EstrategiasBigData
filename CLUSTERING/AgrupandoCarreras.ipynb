{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje No Supervisado: Clustering\n",
    "\n",
    "<img src='https://files.realpython.com/media/centroids_iterations.247379590275.gif'>\n",
    "\n",
    "El aprendizaje no supervisado es una técnica de aprendizaje automático que se emplea con el objeto de descubrir patrones en los datos. Por ejemplo, encontrar los \"grupos\" naturales de clientes (Segmentación de Clientes) en función de sus historiales de compra, buscando patrones, o correlaciones entre estos datos, permitiendo expresar dichos datos en forma comprimida. \n",
    "\n",
    "- La busqueda de patrones es conocida como Clustering o Agrupación\n",
    "- La busqueda de correlación entre los datos es llamada Reducción de dimensionalidad.\n",
    "\n",
    "**Datasets a utilizar:**\n",
    "\n",
    "Un estudio realizado por PayScale Inc., proveedor on-line de datos de sueldos/salarios globales, encuestó a 1,2 millones de graduados, con un mínimo de 10 años de experiencia laboral. Las sujetos provenían de más de 300 escuelas de EE. UU., desde instituciones estatales hasta la Ivy League, y sus ingresos muestran que la materia en la que se especializa puede tener poco que ver con su poder adquisitivo a largo plazo. Se excluyeron a los encuestados que informaron tener títulos avanzados, incluidos M.B.A., M.D.s y J.D.s.\n",
    "\n",
    "\n",
    "**Objetivo:**\n",
    "\n",
    "Responder a la pregunta ¿Qué carreras universitarias tienden a tener mejores ingresos?\n",
    "\n",
    "Veremos:\n",
    "- Limpieza de datos y conversión de tipos de datos\n",
    "- La diferencia de resultados entre escalar o no los datos.\n",
    "- Determinación del número óptimo de clústeres.\n",
    "- Modelado de clústeres con K-Medias.\n",
    "- Visualización de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_DegreesPay = pd.read_csv('data/degrees-that-pay-back.csv')\n",
    "data_DegreesPay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_DegreesPay.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza y curación\n",
    "\n",
    "- Eliminación de caracteres especiales.\n",
    "- Eliminación de \",\" de miles.\n",
    "- Conversión de string a numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de datos\n",
    "data_DegreesPay = data_DegreesPay.astype(str).applymap(lambda x: x.replace(',', ''))\\\n",
    "                .applymap(lambda x: x.replace('$', ''))\n",
    "\n",
    "data_DegreesPay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_DegreesPay.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizó una conversión de todas las columnas a tipo 'object', esto no es lo más correcto, para evitar hacer el código más extenso y complejo se hizo de esta manera.\n",
    "\n",
    "Ahora debemos hacer la conversión a tipo numérico de las columnas que correspondan. \n",
    "\n",
    "El algoritmo estándar de k-medias no se aplica a los datos categóricos:\n",
    "- El espacio muestral para datos categóricos es discreto y no tiene un origen natural.\n",
    "- La función de distancia euclidiana en tal espacio no es realmente significativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos sí alguna carrera se repite\n",
    "print('Número de registros:', data_DegreesPay.shape[0])\n",
    "print('Número de carreras:', data_DegreesPay['Undergraduate Major'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversión de tipo de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardemos las carreras en una variable, para usar luego\n",
    "carreras = data_DegreesPay.iloc[:, 0]\n",
    "\n",
    "# Eliminamos la columna categórica\n",
    "df_DegreesPay = data_DegreesPay.iloc[:, 1:].copy()\n",
    "\n",
    "# Conversión de cada columna a tipo númerico\n",
    "for col in df_DegreesPay.columns:\n",
    "    df_DegreesPay[col] = pd.to_numeric(df_DegreesPay[col], errors='coerce')\n",
    "\n",
    "print(df_DegreesPay.info())\n",
    "df_DegreesPay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expresemos el salario inicial en miles de dólares\n",
    "df_DegreesPay['Starting Median Salary'] = df_DegreesPay['Starting Median Salary']/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado de Datos\n",
    "\n",
    "Antes de modelar los datos con K-Means, apartemos algunos datos de prueba.\n",
    "\n",
    "Y comencemos probando con 5 clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_DegreesPay.sample(n=5, random_state=28)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apartar datos de prueba\n",
    "sample = df_DegreesPay.sample(n=5, random_state=28)\n",
    "\n",
    "# Datos para modelar\n",
    "modeling_sample = df_DegreesPay.drop(index=sample.index)\n",
    "\n",
    "# Creamos la instancia del modelo para 5 números de clusters\n",
    "k=5\n",
    "model = KMeans(n_clusters=k, random_state=28)\n",
    "\n",
    "# Ajustamos el modelo a los datos\n",
    "model.fit(modeling_sample)\n",
    "\n",
    "# Determinar las etiquetas de los clusters de la data de prueba\n",
    "labels = model.predict(modeling_sample)\n",
    "new_labels = model.predict(sample)\n",
    "\n",
    "# Veamos las etiquetas de las carreras\n",
    "print(*labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos las etiquetas de los nuevas carreras\n",
    "print(*new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(modeling_sample, sample, model, xy, axs, scaling=False):\n",
    "    \n",
    "    columns = modeling_sample.columns\n",
    "    # Ajustar el pipeline a los datos\n",
    "    model.fit(modeling_sample)\n",
    "\n",
    "    # Obtención de etiquetas de clusters para los datos provistos\n",
    "    labels = model.predict(modeling_sample)\n",
    "    newlabels = model.predict(sample)\n",
    "\n",
    "\n",
    "    if scaling:\n",
    "        # Obteniendo los centroides de los clusters (en array)\n",
    "        centroids = model[1].cluster_centers_\n",
    "        centroids = scaler.inverse_transform(centroids)        \n",
    "    else:\n",
    "        # Obteniendo los centroides de los clusters (en array)\n",
    "        centroids = model.cluster_centers_\n",
    "        \n",
    "    \n",
    "    for par, ax in zip(xy, axs.ravel()):\n",
    "        col1, col2 = par\n",
    "        col1_name = modeling_sample.columns[col1]\n",
    "        col2_name = modeling_sample.columns[col2]\n",
    "\n",
    "        # Valores de columnas para graficar\n",
    "        x1 = modeling_sample.iloc[:, col1]\n",
    "        x2 = modeling_sample.iloc[:, col2]\n",
    "\n",
    "        # Valores de los centroides para cada columna\n",
    "        centroids_x1 = centroids[:, col1]\n",
    "        centroids_x2 = centroids[:, col2]\n",
    "\n",
    "        # Asignar colores a los clusters\n",
    "        colores=['blue','red','green','cyan','orange','pink','purple', 'yellow']\n",
    "        asignar_labels=[colores[label] for label in labels]\n",
    "        asignar_newlabels=[colores[label] for label in newlabels]\n",
    "        asignar_centroid=[colores[centroid] for centroid in range(centroids.shape[0])]\n",
    "\n",
    "        # Graficar los puntos de datos según los valores de las columnas seleccionadas, c/u de un color según su cluster\n",
    "        ax.scatter(x1, x2, c=asignar_labels, alpha=0.5)\n",
    "\n",
    "        # Graficar los centroides según los valores de las columnas seleccionadas, c/u de un color según su cluster\n",
    "        ax.scatter(centroids_x1, centroids_x2, c=asignar_centroid, marker='o', edgecolors='black', s=60)\n",
    "\n",
    "        # Graficar los puntos nuevos según los valores de las columnas seleccionadas, c/u de un color según su cluster\n",
    "        ax.scatter(sample.iloc[:, col1], sample.iloc[:, col2], c=asignar_newlabels, marker='+', s=90)\n",
    "        ax.set_xlabel(col1_name, fontsize=12)\n",
    "        ax.set_ylabel(col2_name, fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = [(0, 1), (0, 2), (1, 2), (0, 4)]\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "labels = plot_clusters(modeling_sample, sample, model, xy, axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalado de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero dependiendo del tipo de datos con los que esté trabajando, es posible que la agrupación en clústeres no siempre sea tan buena. ¿Hay algo que pueda hacer en tales situaciones para mejorar su agrupación?\n",
    "\n",
    "**Escalado estándar o Estandarización**\n",
    "\n",
    "En la agrupación de KMeans, la varianza de una característica corresponde a su influencia en el algoritmo de agrupación. Para darle una oportunidad a cada característica, los datos deben transformarse para que las características tengan la misma variación. Esto se puede lograr con StandardScaler de scikit-learn. Esto transforma cada característica para que tenga media 0 y varianza 1. Las características \"estandarizadas\" pueden ser muy útiles en información.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar el método de escalado\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Crear instancia de K-Means\n",
    "k=5\n",
    "kmeans = KMeans(n_clusters=k, random_state=28)\n",
    "\n",
    "# Create pipeline: pipeline\n",
    "pipeline = make_pipeline(scaler, kmeans)\n",
    "\n",
    "# Ajustar el pipeline a los datos\n",
    "pipeline.fit(modeling_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = [(0, 1), (0, 2), (1, 2), (0, 4)]\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "labels_scaling = plot_clusters(modeling_sample, sample, pipeline, xy, axs, scaling=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de la calidad de clusters\n",
    "\n",
    "¿Cómo puede estar seguro de que 5 grupos es la elección correcta? ¿Cómo se puede evaluar la calidad de un agrupamiento?\n",
    "\n",
    "- **Medición de la calidad de la agrupación**\n",
    "\n",
    "Necesitamos una forma de medir la calidad de una agrupación que utilice solo las agrupaciones y las muestras en sí. Un buen agrupamiento tiene grupos reducidos, lo que significa que las muestras de cada grupo se agrupan, no se dispersan.\n",
    "\n",
    "- **La inercia mide la calidad de la agrupación**\n",
    "\n",
    "La \"inercia\" puede medir la dispersión de las muestras dentro de cada grupo. La inercia mide qué tan lejos están las muestras de sus centroides. \n",
    "\n",
    "Lo ideal es obtener grupos que no estén dispersos, por lo que los valores más bajos de inercia son mejores. \n",
    "\n",
    "K-Means tiene como objetivo colocar los clústeres de una manera que minimice la inercia.\n",
    "\n",
    "- **Número de clusters óptimo**\n",
    "\n",
    "Aquí hay una gráfica de los valores de inercia de agrupaciones del conjunto de datos del iris con diferentes números de agrupaciones. Nuestro modelo de kmeans con 3 grupos tiene una inercia relativamente baja, lo cual es genial. Pero observe que la inercia continúa disminuyendo lentamente. Entonces, ¿cuál es la mejor cantidad de clústeres para elegir?\n",
    "\n",
    "- **¿Cuántos clusters elegir?**\n",
    "\n",
    "Una buena agrupación tiene agrupaciones estrechas (baja inercia). Pero también, el menor número de clústeres. \n",
    "\n",
    "Una buena regla general, basada en la \"Elbow Curve\", consiste en elegir un codo en la gráfica de inercia, aquel punto donde la inercia comienza a disminuir más lentamente.\n",
    "\n",
    "\n",
    "**Método del Codo o Elbow Method**\n",
    "Este método gráfica el porcentaje de varianza vs el número de clusters. El codo de la curva indica el punto óptimo en el que agregar más grupos ya no explicará una cantidad significativa de la varianza. \n",
    "\n",
    "Los métodos más conocidos y empleados para obtener el número óptimo de clusters o agrupaciones, es el Método del Codo y el método de Siluetas o [Silhouette Method](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html?highlight=kmeans).\n",
    "\n",
    "\n",
    "Generalmente no sabemos el número de clusters o agrupaciones son las óptimas, así que probemos con distintos números. Intentemos para k números de clusters desde 1 a 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "18"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# k clusters de 1 a 10\n",
    "ks = range(1, 11)\n",
    "inertias = []\n",
    "\n",
    "sample_scaled = scaler.fit_transform(modeling_sample)\n",
    "\n",
    "# Creamos las diferentes instancias del modelo con cada k números de clusters\n",
    "kmeans = [KMeans(n_clusters=k, random_state=28) for k in ks]\n",
    "\n",
    "# Calculo de métrica para cada modelo\n",
    "inertias = [model.fit(sample_scaled).inertia_ for model in kmeans]\n",
    "    \n",
    "# Graficar la variación explicada en función del número de clusters\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(ks, inertias, '-o')\n",
    "plt.title('Elbow Curve')\n",
    "plt.xlabel('Número de Clusters')\n",
    "plt.ylabel('Inercia')\n",
    "plt.xticks(ks)\n",
    "plt.box(False)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KMeans instance: kmeans\n",
    "k_optimo = 3\n",
    "kmeans = KMeans(n_clusters=k_optimo)\n",
    "\n",
    "# Create pipeline: pipeline\n",
    "pipeline = make_pipeline(scaler, kmeans)\n",
    "\n",
    "# Ajustar el pipeline a los datos\n",
    "pipeline.fit(modeling_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = [(0, 1), (0, 2), (1, 2), (0, 4)]\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "clusters_labels = plot_clusters(modeling_sample, sample, pipeline, xy, axs, scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos las etiquetas de los clusters \n",
    "print(*clusters_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un dataframe con los resultados\n",
    "results = modeling_sample.copy()\n",
    "results['cluster'] = clusters_labels\n",
    "results['carreras'] = carreras[results.index]\n",
    "\n",
    "# Veamos las carreras para cada cluster\n",
    "for cluster in range(k_optimo):\n",
    "    carreras_cluster = results.loc[results['cluster']==cluster, 'carreras']\n",
    "    print(f\"Carreras del cluster {cluster}:\\n{carreras_cluster.values}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
