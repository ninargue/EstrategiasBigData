{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje Supervisado: Regresión\n",
    "\n",
    "\n",
    "***Agradecimientos:***\n",
    "- Dataset: UCI Machine Learning Repository\n",
    "- Data link : https://archive.ics.uci.edu/ml/datasets/auto+mpg\n",
    "\n",
    "\n",
    "Los datos se refieren al consumo de combustible del ciclo de la ciudad en millas por galón.\n",
    "El conjunto de datos se utilizó en la American Statistical Association Exposition de 1983.\n",
    "\n",
    "- Número de instancias: 398\n",
    "\n",
    "- Número de atributos: 9\n",
    "\n",
    "- Información de atributos:\n",
    "    - mpg: continuous\n",
    "    - cylinders: discrete\n",
    "    - displacement: continuous\n",
    "    - horsepower: continuous\n",
    "    - weight: continuous\n",
    "    - acceleration: continuous\n",
    "    - model year: discrete\n",
    "    - origin: discrete\n",
    "    - car name: string (unique for each instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirección de descarga\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "\n",
    "# Obtener datos desde la url\n",
    "r = requests.get(url)\n",
    "\n",
    "# Cambiar tabulación (\\t) por un espacio\n",
    "string = r.text.replace(\"\\t\",\" \")\n",
    "\n",
    "# Para cargar esta cadena de texto como un archivo, podemos usar StringIO integrado en Python\n",
    "file = StringIO(string)\n",
    "column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', \n",
    "                'acceleration', 'model year', 'origin', 'car name']\n",
    "\n",
    "data_mpgAutos = pd.read_csv(file, sep=\"\\s+\", header=None, names=column_names)\n",
    "\n",
    "# Veamos las primeras 5 filas del dataframe\n",
    "data_mpgAutos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mpgAutos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas_de_modelos(y_train, y_pred_train, y_test, y_pred):\n",
    "    R2_train = r2_score(y_train, y_pred_train)\n",
    "    R2_test = r2_score(y_test, y_pred)\n",
    "    RMSE_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    RMSE_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    MAE_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    MAE_test = mean_absolute_error(y_test, y_pred)\n",
    "    print('\\nMétricas del Modelo de Regresión Lineal')\n",
    "    print(f\"R2 train: {R2_train:.4f}\")\n",
    "    print(f\"R2 test: {R2_test:.4f}\")\n",
    "    print(f\"RMSE train: {RMSE_train:.2f}\")\n",
    "    print(f\"RMSE test: {RMSE_test:.2f}\")\n",
    "    print(f\"MAE train: {MAE_train:.2f}\")\n",
    "    print(f\"MAE test: {MAE_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspección de datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mpgAutos['horsepower'] = pd.to_numeric(data_mpgAutos['horsepower'], errors='coerce')\n",
    "data_mpgAutos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mpgAutos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mpgAutos[data_mpgAutos['horsepower'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mpgAutos[data_mpgAutos['cylinders']==4].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mpgAutos[data_mpgAutos['cylinders']==6].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputación de datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_4cyl = round(data_mpgAutos.loc[data_mpgAutos['cylinders']==4, 'horsepower'].mean(), 0)\n",
    "mean_4cyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (data_mpgAutos['horsepower'].isnull()) & (data_mpgAutos['cylinders']==4)\n",
    "data_mpgAutos.loc[mask] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mpgAutos.loc[mask, 'horsepower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mpgAutos.loc[mask, 'horsepower'] = mean_4cyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mpgAutos.loc[mask, 'horsepower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_6cyl = round(data_mpgAutos.loc[data_mpgAutos['cylinders']==6, 'horsepower'].mean(), 0)\n",
    "mask = (data_mpgAutos['horsepower'].isnull()) & (data_mpgAutos['cylinders']==6)\n",
    "data_mpgAutos.loc[mask, 'horsepower'] = mean_6cyl\n",
    "\n",
    "# Inspección de los datos para corroborar la imputación de datos faltantes\n",
    "data_mpgAutos.loc[mask, 'horsepower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos que no hay datos faltantes\n",
    "data_mpgAutos.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspeccionamos la variable 'origin'\n",
    "data_mpgAutos['origin'].astype('category').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas de las variables\n",
    "data_mpgAutos.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlación de Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data_mpgAutos.drop(columns=['car name', 'origin']).corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(7, 5))\n",
    "    ax = sns.heatmap(corr, annot=True, mask=mask, square=True, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mpgAutos.groupby(['origin'])['mpg'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado de datos\n",
    "\n",
    "Links relacionados: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html#sklearn.tree.plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "\n",
    "# Semilla para inicializar el generador de números aleatorios\n",
    "seed = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data de regresores\n",
    "X = data_mpgAutos.drop(columns=['mpg', 'car name'])\n",
    "X_dummy = pd.get_dummies(X['origin'], drop_first=True)\n",
    "X = pd.concat([X, X_dummy.add_prefix('origin_')], axis=1)\n",
    "\n",
    "# Data de variable target o regresora\n",
    "y = data_mpgAutos['mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos las variables dummy\n",
    "X_dummy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar column 'origin' (ya la tenemos como variables ficiticias)\n",
    "# Division datasets de entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.drop(columns=['origin']), y, test_size=0.25, random_state=seed)\n",
    "\n",
    "# Dimensiones de los dataframes de train y test\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Regresión Lineal (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar el modelo de Regresión Lineal\n",
    "model = LinearRegression()\n",
    "\n",
    "# Ajuste del modelo a los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones a partir de los datos entrenamiento y test\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Gráfico de comparación datos de target real vs predicciones\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_test, y_pred, '*')\n",
    "ax.set_title('Consumo de Combustible en Millas/galón\\nValores reales vs predichos (Test)')\n",
    "ax.set_xlabel('Valores reales')\n",
    "ax.set_ylabel('Valores predichos')\n",
    "# Borrar bordes del gráfico\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.axline((0, 0), slope=1, ls='--', color='r')\n",
    "plt.show()\n",
    "\n",
    "# Calculo de Métricas de entrenamiento y test\n",
    "metricas_de_modelos(y_train, y_pred_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns  #[str(col) for col in X_train.columns]\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(cols, model.coef_)\n",
    "ax.set_title('Coeficientes del Modelo')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.grid(ls='--')\n",
    "plt.show()\n",
    "\n",
    "# Intercepción y coeficientes del modelo\n",
    "print(f\"\\nIntercepción: {model.intercept_:.2f}\\n\")\n",
    "round(pd.DataFrame(model.coef_.reshape(1,-1), columns=cols), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Regresión con Árboles de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar column 'origin' (la tenemos como variables ficticias)\n",
    "# Division datasets de entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.drop(columns=['origin_2', 'origin_3']), y, \n",
    "                                                           test_size=0.25, random_state=seed)\n",
    "\n",
    "# Dimensiones de los dataframes de train y test\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar el modelo de Regresión Lineal\n",
    "model = DecisionTreeRegressor(random_state=seed)\n",
    "\n",
    "# Ajuste del modelo a los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones a partir de los datos entrenamiento y test\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Gráfico de comparación datos de target real vs predicciones\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_test, y_pred, '*')\n",
    "ax.set_title('Consumo de Combustible en Millas/galón\\nValores reales vs predichos (Test)')\n",
    "ax.set_xlabel('Valores reales')\n",
    "ax.set_ylabel('Valores predichos')\n",
    "# Borrar bordes del gráfico\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.axline((0, 0), slope=1, ls='--', color='r')\n",
    "plt.show()\n",
    "\n",
    "# Calculo de Métricas de entrenamiento y test\n",
    "metricas_de_modelos(y_train, y_pred_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los parámetros del modelo\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns\n",
    "fig, ax = plt.subplots()\n",
    "feature_importances = pd.DataFrame(model.feature_importances_, index=cols).sort_values(0)\n",
    "feature_importances.plot(kind='barh', legend=False, ax=ax)\n",
    "ax.set_title('Coeficientes del Modelo')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.grid(ls='--')\n",
    "plt.show()\n",
    "round(feature_importances.T, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfica del Árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "tree.plot_tree(model, max_depth=None, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 10))\n",
    "tree.plot_tree(model, max_depth=2, ax=ax, feature_names=cols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting - Underfitting - Generalized Error\n",
    "\n",
    "Su objetivo es encontrar un modelo que se aproxime mejor a una FUNCIÓN. Al entrenar fhat, debes asegurarte de que el ruido se descarta tanto como sea posible. Debería lograrse un error predictivo bajo en el conjuntos de datos nuevos (test.\n",
    "\n",
    "Puede encontrar dos dificultades al ajustar los datos a la FUNCIÓN. \n",
    "- **Sobreajuste (overfitting)**: cuando la FUNCIÓN se adapta al ruido en el conjunto de entrenamiento. Su poder predictivo en conjuntos de datos no vistos es **bastante bajo**. El modelo memoriza el ruido presente en el conjunto de entrenamiento y luego no es capaz de predecir ante valores nuevos. Dicho modelo logra un *error de conjunto de entrenamiento bajo y un error de conjunto de prueba alto*.\n",
    "\n",
    "    Un error de entrenamiento bajo y un error de generalización alto indica overfitting, el modelo ha aprendido los datos \"de memoria\", y no es capaz de generalizar para adaptarse a datos nuevos.\n",
    "\n",
    "- **Desajuste (underfitting)**: cuando la FUNCIÓN no es lo suficientemente flexible para aproximarse al conjunto de entrenamiento. Cuando un modelo no se ajusta a los datos, el error del conjunto de entrenamiento es aproximadamente igual al error del conjunto de prueba. Siendo ambos errores altos. Dicho modelo no es lo suficientemente flexible para capturar la dependencia entre predictores y variable respuesta.\n",
    "\n",
    "El **error de generalización** de un modelo le dice cuánto generaliza en datos no vistos. Se puede descomponer en 3 términos: \n",
    "\n",
    "1. sesgo \n",
    "1. varianza y\n",
    "1. error irreductible, donde el error irreducible es la contribución del ruido al error.\n",
    "\n",
    "\n",
    "<img align=right src=https://datacated.com/wp-content/uploads/2019/02/1_9hPX9pAO3jqLrzt0IE3JzA.png width=\"600\" height=\"700\"/>\n",
    "\n",
    "**Sesgo o Bias**: indica, en promedio, cuánto y predicho e y real son diferentes. El modelo no es lo suficientemente flexible para aproximarse a la función verdadera. Los modelos de alto sesgo conducen a un desajuste.\n",
    "\n",
    "**Varianza**: indica cuánta inconsistencia existe entre diferentes conjuntos de entrenamiento. Los modelos de alta variación conducen a un sobreajuste.\n",
    "\n",
    "La **complejidad de un modelo** establece su flexibilidad para aproximarse a la función verdadera f.\n",
    "\n",
    "**Bias-Variance Tradeoff**: El siguiente diagrama muestra cómo la *mejor complejidad del modelo* corresponde al *menor error de generalización*. Cuando aumenta la complejidad del modelo, la varianza aumenta mientras que el sesgo disminuye. Por el contrario, cuando la complejidad del modelo disminuye, la varianza disminuye y el sesgo aumenta. El objetivo es encontrar la complejidad del modelo que logre el menor error de generalización. Dado que este error es la suma de los tres términos ya mencionados, y el error irreducible es constante, es necesario encontrar un equilibrio entre el sesgo y la varianza.\n",
    "\n",
    "Siempre se verá que a medida que uno aumenta, el otro disminuye. Esto se conoce como **compensación de sesgo-varianza**.\n",
    "\n",
    "<p align=\"center\">\n",
    " <img src=https://miro.medium.com/max/2048/0*QPOQrv6TZm6FVMd1.png width=\"400\" height=\"480\">\n",
    "</p>\n",
    "\n",
    "https://ars.els-cdn.com/content/image/1-s2.0-S0167739X1500223X-gr11.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejoremos el modelo DecisionTree\n",
    "\n",
    "Links de referencia:\n",
    "\n",
    "- [Post pruning decision trees with cost complexity pruning](https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html#sphx-glr-auto-examples-tree-plot-cost-complexity-pruning-py)\n",
    "- [Decision Trees](https://scikit-learn.org/stable/modules/tree.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar el modelo de Regresión Lineal\n",
    "model = DecisionTreeRegressor(\n",
    "                                criterion='mse',     # función para medir la calidad de un split (mse, mae, poisson, friedman_mse)\n",
    "                                splitter='best',     # La estrategia utilizada para elegir la división en cada nodo (best, random)\n",
    "                                max_depth=6,         # Máxima profundidad del árbol\n",
    "                                min_samples_split=2,  # Número mínimo de muestra necesarias para dividir un nodo interno (int, float)\n",
    "                                min_samples_leaf=2,   # Número mínimo de muestras necesarias en un nodo hoja (int, float)\n",
    "                                min_weight_fraction_leaf=0.0,\n",
    "                                max_features=None,   \n",
    "                                random_state=seed,\n",
    "                                max_leaf_nodes=6,            # Máximo número de nodos hoja\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                min_impurity_split=None,     # Umbral de parada temprana en el crecimiento de los árboles\n",
    "                                ccp_alpha=0.0,                 # Poda de complejidad de costo mínimo\n",
    "                             )\n",
    "\n",
    "# Ajuste del modelo a los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones a partir de los datos entrenamiento y test\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Gráfico de comparación datos de target real vs predicciones\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_test, y_pred, '*')\n",
    "ax.set_title('Consumo de Combustible en Millas/galón\\nValores reales vs predichos (Test)')\n",
    "ax.set_xlabel('Valores reales')\n",
    "ax.set_ylabel('Valores predichos')\n",
    "# Borrar bordes del gráfico\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.axline((0, 0), slope=1, ls='--', color='r')\n",
    "plt.show()\n",
    "\n",
    "# Calculo de Métricas de entrenamiento y test\n",
    "metricas_de_modelos(y_train, y_pred_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 10))\n",
    "tree.plot_tree(model, max_depth=None, ax=ax, feature_names=cols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar el modelo de Regresión Lineal\n",
    "model = DecisionTreeRegressor(\n",
    "                                criterion='mse',\n",
    "                                splitter='best',\n",
    "                                max_depth=6,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=2,\n",
    "                                min_weight_fraction_leaf=0.0,\n",
    "                                max_features=None,\n",
    "                                random_state=seed,\n",
    "                                max_leaf_nodes=10,\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                min_impurity_split=None,\n",
    "                                ccp_alpha=0.0,\n",
    "                             )\n",
    "\n",
    "# Ajuste del modelo a los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones a partir de los datos entrenamiento y test\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Gráfico de comparación datos de target real vs predicciones\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_test, y_pred, '*')\n",
    "ax.set_title('Consumo de Combustible en Millas/galón\\nValores reales vs predichos (Test)')\n",
    "ax.set_xlabel('Valores reales')\n",
    "ax.set_ylabel('Valores predichos')\n",
    "# Borrar bordes del gráfico\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.axline((0, 0), slope=1, ls='--', color='r')\n",
    "plt.show()\n",
    "\n",
    "# Calculo de Métricas de entrenamiento y test\n",
    "metricas_de_modelos(y_train, y_pred_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 10))\n",
    "tree.plot_tree(model, max_depth=None, ax=ax, feature_names=cols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar el modelo de Regresión Lineal\n",
    "model = DecisionTreeRegressor(\n",
    "                                criterion='mse',\n",
    "                                splitter='best',\n",
    "                                max_depth=6,\n",
    "                                min_samples_split=3,\n",
    "                                min_samples_leaf=2,\n",
    "                                min_weight_fraction_leaf=0.0,\n",
    "                                max_features=None,\n",
    "                                random_state=seed,\n",
    "                                max_leaf_nodes=6,\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                min_impurity_split=None,\n",
    "                                ccp_alpha=0.0,\n",
    "                             )\n",
    "\n",
    "# Ajuste del modelo a los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones a partir de los datos entrenamiento y test\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Gráfico de comparación datos de target real vs predicciones\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_test, y_pred, '*')\n",
    "ax.set_title('Consumo de Combustible en Millas/galón\\nValores reales vs predichos (Test)')\n",
    "ax.set_xlabel('Valores reales')\n",
    "ax.set_ylabel('Valores predichos')\n",
    "# Borrar bordes del gráfico\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.axline((0, 0), slope=1, ls='--', color='r')\n",
    "plt.show()\n",
    "\n",
    "# Calculo de Métricas de entrenamiento y test\n",
    "metricas_de_modelos(y_train, y_pred_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 10))\n",
    "tree.plot_tree(model, max_depth=None, ax=ax, feature_names=cols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar el modelo de Regresión Lineal\n",
    "model = DecisionTreeRegressor(\n",
    "                                criterion='mse',\n",
    "                                splitter='best',\n",
    "                                max_depth=None,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=2,\n",
    "                                min_weight_fraction_leaf=0.0,\n",
    "                                max_features=None,\n",
    "                                random_state=seed,\n",
    "                                max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                min_impurity_split=None,\n",
    "                                ccp_alpha=0.3,                 \n",
    "                             )\n",
    "\n",
    "# Ajuste del modelo a los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones a partir de los datos entrenamiento y test\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Gráfico de comparación datos de target real vs predicciones\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_test, y_pred, '*')\n",
    "ax.set_title('Consumo de Combustible en Millas/galón\\nValores reales vs predichos (Test)')\n",
    "ax.set_xlabel('Valores reales')\n",
    "ax.set_ylabel('Valores predichos')\n",
    "# Borrar bordes del gráfico\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.axline((0, 0), slope=1, ls='--', color='r')\n",
    "plt.show()\n",
    "\n",
    "# Calculo de Métricas de entrenamiento y test\n",
    "metricas_de_modelos(y_train, y_pred_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 10))\n",
    "tree.plot_tree(model, max_depth=None, ax=ax, feature_names=cols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
